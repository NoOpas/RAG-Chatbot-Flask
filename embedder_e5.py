import psycopg2
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from loguru import logger 
import sys # –î–ª—è –ª–æ–≥–≥–µ—Ä–∞

# === CONFIGURATION ===
DB_CONFIG = {
    "database": "my_db",
    "user": "my_user",
    "password": "my_password",
    "host": "localhost"
}

MODEL_PATH = "./models/multilingual-e5-small"
BATCH_SIZE = 32
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50

# === –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LOGURU ===
logger.remove()

logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="INFO",
    colorize=True
)

# –¥–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏ (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –ª–æ–≥–∞, –¥–æ 100 MB –∫–∞–∂–¥—ã–π)
logger.add(
    "logs/vectorization_{time:YYYY-MM-DD}.log",
    rotation="100 MB",
    retention=3,
    level="DEBUG",
    encoding="utf-8"
)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===
logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
model = SentenceTransformer(MODEL_PATH, device="cpu")
logger.success("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

# === –°–æ–∑–¥–∞–µ—Ç –¥–µ–ª–∏—Ç–µ–ª—å —Ç–µ–∫—Å—Ç–∞ ===
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=CHUNK_SIZE,
    chunk_overlap=CHUNK_OVERLAP,
    separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""],
    length_function=len,
)

# === –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ ===
def get_db_connection():
    return psycopg2.connect(**DB_CONFIG)

conn = get_db_connection()
cursor = conn.cursor()

# === 4. –°–±–æ—Ä –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ ===
logger.info("–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –∏–∑ –ë–î –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
cursor.execute("""
    SELECT id, url, content 
    FROM main_table
    WHERE content IS NOT NULL AND content != ''
""")

rows = cursor.fetchall()
logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(rows)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")

# === –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã document_chunks, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç ===
logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞/—Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã main_table_chunks...")
cursor.execute("""
    CREATE TABLE IF NOT EXISTS main_table_chunks (
        id SERIAL PRIMARY KEY,
        original_id INT REFERENCES main_table(id) ON DELETE CASCADE,
        url TEXT,
        content TEXT,
        embedding VECTOR(384),
        created_at TIMESTAMPTZ DEFAULT NOW()
    );
""")
conn.commit()
logger.success("‚úÖ –¢–∞–±–ª–∏—Ü–∞ main_table_chunks –≥–æ—Ç–æ–≤–∞.")

# === –ó–∞–ø–∏—Å—å -> –ß–∞–Ω–∫ -> –≠–º–±–µ–¥–¥–∏–Ω–≥ -> –í—Å—Ç–∞–≤–∫–∞ –≤ –±–∞–∑—É ===
processed_count = 0

for idx, (row_id, url, content) in enumerate(rows, start=1):
    try:
        # –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –∫—É—Å–∫–∏
        chunks = text_splitter.split_text(content)
        logger.debug(f"ID {row_id}: –ø–æ–ª—É—á–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤.")

        if not chunks:
            logger.warning(f"ID {row_id}: –ø—É—Å—Ç—ã–µ —á–∞–Ω–∫–∏ –ø–æ—Å–ª–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è ‚Äî –ø—Ä–æ–ø—É—Å–∫.")
            continue

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –¥–ª—è E5
        prefixed_chunks = ["passage: " + chunk for chunk in chunks]

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        embeddings = model.encode(
            prefixed_chunks,
            batch_size=BATCH_SIZE,
            show_progress_bar=False,
            convert_to_numpy=True,
            normalize_embeddings=True
        )

        # –í—Å—Ç–∞–≤–∫–∞ –Ω–æ–≤–æ–≥–æ –∫—É—Å–∫–∞ –≤ –±–∞–∑—É –∫–∞–∫ –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
        for chunk_text, embedding_vector in zip(chunks, embeddings):
            cursor.execute("""
                INSERT INTO main_table_chunks (original_id, url, content, embedding)
                VALUES (%s, %s, %s, %s)
            """, (row_id, url, chunk_text, embedding_vector.tolist()))

        processed_count += 1

        # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã—Ö 10 –∑–∞–ø–∏—Å–µ–π
        if processed_count % 10 == 0:
            conn.commit()
            logger.info(f"üíæ –ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {processed_count} –∏–∑ {len(rows)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. ({idx}/{len(rows)})")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ ID {row_id}: {e}")
        logger.exception(e)  # –õ–æ–≥–∞–µ–º –≤–µ—Å—å –æ—Ç–≤–µ—Ç –æ—à–∏–±–∫–∏
        continue

# –ü–æ—Å–ª–µ–¥–Ω—è—è —Ñ–∏–∫—Å–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
conn.commit()
logger.success(f"üèÅ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")

# === –°–æ–∑–¥–∞–Ω–∏–µ HNSW (–∞–ª–≥–æ—Ä–∏—Ç–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π) –∏–Ω–¥–µ–∫—Å–∞ ===
logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ HNSW –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º...")
try:
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS hnsw_embedding_idx 
        ON main_table_chunks 
        USING hnsw (embedding vector_cosine_ops);
    """)
    conn.commit()
    logger.success("‚úÖ –ò–Ω–¥–µ–∫—Å hnsw_embedding_idx —Å–æ–∑–¥–∞–Ω.")
except Exception as e:
    logger.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å: {e}")
    logger.exception(e)

# === –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ ===
cursor.close()
conn.close()
logger.info("üîå –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫—Ä—ã—Ç–æ.")

# –í—ã–≤–æ–¥ –ø—Ä–∏ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã
logger.info("="*60)
logger.info("üìä –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {processed_count}")
logger.info(f"üìÇ –õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: logs/vectorization_*.log")
logger.info("="*60)
