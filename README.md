# ğŸ“„ RAG Chatbot for Educational & Reference Portal  
> Local LLM assistant based on Saiga-Mistral-7B with PostgreSQL + pgvector backend  

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.x-black)](https://flask.palletsprojects.com)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

---

## ğŸ“‘ Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ°Ğ½Ğ¸Ğµ / Table of Contents

- [ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ](#-Ñ€ÑƒÑÑĞºĞ°Ñ-Ğ²ĞµÑ€ÑĞ¸Ñ)
  - [ĞĞ±Ğ·Ğ¾Ñ€](#-Ğ¾Ğ±Ğ·Ğ¾Ñ€)
  - [Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸](#Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ-Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸)
  - [Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑÑ‚ĞµĞº](#Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹-ÑÑ‚ĞµĞº)
  - [Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°](#ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°-Ğ¸-Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°)
    - [Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ](#51-Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ)
    - [ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°](#52-ĞºĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ-Ğ¸-ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°)
    - [ĞœĞ¾Ğ´ĞµĞ»Ğ¸](#53-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸)
    - [ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…](#54-Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°-Ğ±Ğ°Ğ·Ñ‹-Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)
    - [ĞĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ (`uv`)](#55-Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ-uv)
    - [Ğ—Ğ°Ğ¿ÑƒÑĞº](#56-Ğ·Ğ°Ğ¿ÑƒÑĞº)
  - [Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°](#ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°-Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°)
  - [ĞšĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ](#ĞºĞ°Ğº-Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ)
  - [ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ](#ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ)

- [ğŸ‡¬ğŸ‡§ English version](#-english-version)
  - [Overview](#-overview)
  - [Implemented Features](#implemented-features)
  - [Tech Stack](#tech-stack)
  - [Installation & Setup](#installation--setup)
    - [Requirements](#requirements)
    - [Clone & Install](#clone--install)
    - [Models](#models)
    - [Database Setup](#database-setup)
    - [Environment (`uv`)](#environment-uv)
    - [Run](#run)
  - [Project Structure](#project-structure)
  - [How It Works](#how-it-works)
  - [Configuration](#configuration)

---

<a name="ru-version"></a>
# ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ

## ğŸ“– ĞĞ±Ğ·Ğ¾Ñ€

Ğ­Ñ‚Ğ¾ Ğ²ĞµĞ±-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑĞ¼ Ğ·Ğ°Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ Ğ¿Ğ¾ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ°Ğ¼ ÑƒÑ‡ĞµĞ±Ğ½Ğ¾-ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ»Ğ°. ĞÑ‚Ğ²ĞµÑ‚Ñ‹ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒÑÑ‚ÑÑ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ **Saiga-Mistral-7B-GPTQ** Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ñ… Ñ‡ĞµÑ€ĞµĞ· ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ² **PostgreSQL + pgvector**.

**ĞÑĞ¾Ğ±ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸**:
- âœ… ĞŸĞ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ (SSE) â€” Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ğ¿Ğ¾ÑĞ²Ğ»ÑÑÑ‚ÑÑ Ğ¿Ğ¾ Ğ¼ĞµÑ€Ğµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
- âœ… Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ Ğ¿Ğ¾Ğ´ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ¼ â€” Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ñ†Ğ¸Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- âœ… ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸
- âœ… ĞĞ¸Ğ·ĞºĞ¸Ğµ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğº GPU (Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ 8 Ğ“Ğ‘ VRAM)
- âœ… ĞŸĞ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº â€” Ğ½Ğ¸ĞºĞ°ĞºĞ¸Ñ… Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… API

---

## Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸

- ğŸ§  **RAG-Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°**: Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ â†’ Ğ ĞµÑ€Ğ°Ğ½ĞºĞ¸Ğ½Ğ³ â†’ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ  
- ğŸ“¡ **Ğ¡Ñ‚Ñ€Ğ¸Ğ¼Ğ¸Ğ½Ğ³ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²**: ĞŸĞ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾Ğµ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² (ĞºĞ°Ğº Ğ² ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ‡Ğ°Ñ‚-Ğ±Ğ¾Ñ‚Ğ°Ñ…)  
- ğŸ“š **Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ñ†Ğ¸Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ**: ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ ÑĞ¾Ğ¿Ñ€Ğ¾Ğ²Ğ¾Ğ¶Ğ´Ğ°ĞµÑ‚ÑÑ ÑÑÑ‹Ğ»ĞºĞ°Ğ¼Ğ¸ Ğ½Ğ° Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸  
- ğŸŒ **Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ**: Ğ§Ğ¸ÑÑ‚Ñ‹Ğ¹ UI Ñ Ğ¿Ñ€Ğ¾ĞºÑ€ÑƒÑ‚ĞºĞ¾Ğ¹, ĞºĞ½Ğ¾Ğ¿ĞºĞ¾Ğ¹ Ğ²Ğ½Ğ¸Ğ·, Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ñ‡Ğ°Ñ‚Ğ¾Ğ¼  
- ğŸ“Š **Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ**: `loguru` â€” ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ + Ñ„Ğ°Ğ¹Ğ», Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº  
- ğŸ”’ **Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº**: Ğ’ÑĞµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ²Ğ°ÑˆĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğµ â€” Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ½Ğ¾  

---

## Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑÑ‚ĞµĞº

| Ğ¡Ğ»Ğ¾Ğ¹ | Ğ¢ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ | ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ° |
|------|------------|----------------|
| **Backend** | Flask 2.x, Python 3.10+ | Ğ›Ñ‘Ğ³ĞºĞ¾Ğ²ĞµÑĞ½Ñ‹Ğ¹, Ğ±Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°, Ğ¸Ğ´ĞµĞ°Ğ»ĞµĞ½ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾Ñ‚Ğ¸Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½Ğ° |
| **LLM** | Saiga-Mistral-7B-GPTQ (4-bit) | ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½Ğ° GPU Ñ 8+ Ğ“Ğ‘ VRAM |
| **Embeddings** | `multilingual-e5-small` (384d) | Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾ ÑĞ·Ñ‹ĞºĞ°, Ğ½Ğ¸Ğ·ĞºĞ¾Ğµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ |
| **Vector DB** | PostgreSQL 15+ + `pgvector` | ĞĞ°Ğ´Ñ‘Ğ¶Ğ½Ğ¾, Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾, Ğ»ĞµĞ³ĞºĞ¾ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ‘Ğ” |
| **Frontend** | Vanilla JS + SSE | ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¾, Ğ±ĞµĞ· Ñ‚ÑĞ¶Ñ‘Ğ»Ñ‹Ñ… Ñ„Ñ€ĞµĞ¹Ğ¼Ğ²Ğ¾Ñ€ĞºĞ¾Ğ², Ğ±Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° |
| **Logging** | `loguru` | Ğ¦Ğ²ĞµÑ‚Ğ½Ñ‹Ğµ Ğ»Ğ¾Ğ³Ğ¸ Ğ² ĞºĞ¾Ğ½ÑĞ¾Ğ»Ğ¸ + Ñ€Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ², thread-safe |
| **Packaging** | `uv` | Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ¸ Ğ²Ğ¸Ñ€Ñ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğ¹ Ğ¾Ñ‚ Astral |
| **Hardware** | NVIDIA GPU â‰¥ 8 Ğ“Ğ‘ VRAM | ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² 4-Ğ±Ğ¸Ñ‚Ğ½Ğ¾Ğ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ |

---

## Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ°

### 5.1 Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

- Python 3.10+
- [uv](https://docs.astral.sh/uv/) â€” ultra-fast Python package installer & resolver
- PostgreSQL 15+ Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸ĞµĞ¼ [`pgvector`](https://github.com/pgvector/pgvector)
- NVIDIA GPU (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ â‰¥ 8 Ğ“Ğ‘ VRAM)

> ğŸ’¡ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ `uv`:  
> ```bash
> curl -LsSf https://astral.sh/uv/install.sh | sh
> ```

---

### 5.2 ĞšĞ»Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°

```bash
git clone https://github.com/NoOpas/RAG-Chatbot-Flask.git
cd RAG-Chatbot-Flask
uv venv          # ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ .venv
uv sync          # ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ· pyproject.toml
```

---

### 5.3 ĞœĞ¾Ğ´ĞµĞ»Ğ¸

Ğ¡ĞºĞ°Ñ‡Ğ°Ğ¹Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¿Ğ¾Ğ¼ĞµÑÑ‚Ğ¸Ñ‚Ğµ Ğ² `./models/`:

```
./models/
â”œâ”€â”€ saiga_mistral_7b-GPTQ/
â””â”€â”€ multilingual-e5-small/
```

> ğŸ“Œ **Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ± 1: `git lfs`** (Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)
> ```bash
> git lfs install
> git clone https://huggingface.co/TheBloke/saiga_mistral_7b-GPTQ models/saiga_mistral_7b-GPTQ
> git clone https://huggingface.co/intfloat/multilingual-e5-small models/multilingual-e5-small
> ```
>
> ğŸ“Œ **Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ± 2: Hugging Face CLI**
> ```bash
> uv add huggingface-hub
> uv run huggingface-cli download TheBloke/saiga_mistral_7b-GPTQ --local-dir ./models/saiga_mistral_7b-GPTQ
> uv run huggingface-cli download intfloat/multilingual-e5-small --local-dir ./models/multilingual-e5-small
> ```

---

### 5.4 ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

#### Ğ¨Ğ°Ğ³ 1: Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° (`sp_parse_vectors`)

Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ±Ñ‹Ğ»Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ»Ğ°.  
ĞŸĞ¾Ğ´Ğ¾Ğ±Ğ½ÑƒÑ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ, Ğ½Ğ¾ ÑÑ‚Ğ¾ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ½Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾.

| id | url | content |
|----|-----|---------|
| 1 | `http://sp.giprovostokneft.ru/educationalhelpcenter` | `"Ğ£Ñ‡ĞµĞ±Ğ½Ğ¾-ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ» - Ğ”Ğ¾Ğ¼Ğ°ÑˆĞ½ÑÑ Ğ”Ğ¾Ğ±Ñ€Ğ¾ Ğ¿Ğ¾Ğ¶Ğ°Ğ»Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸..."` |
| 2 | `http://sp.giprovostokneft.ru/educationalhelpcenter/ING_RU` | `"Ğ˜Ğ½Ğ¶-Ğ Ğ£ - Ğ”Ğ¾Ğ¼Ğ°ÑˆĞ½ÑÑ Ğ¡Ğ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ñ€ĞµÑÑƒÑ€Ñ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ½Ğ¾Ğ¼Ñƒ ĞºĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑÑƒ Ğ˜Ğ½Ğ¶-Ğ Ğ£..."` |
| 3 | `http://sp.giprovostokneft.ru/educationalhelpcenter/MagiCAD` | `"MagiCAD - Ğ”Ğ¾Ğ¼Ğ°ÑˆĞ½ÑÑ Ğ¡Ğ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ñ€ĞµÑÑƒÑ€Ñ Ğ¿Ğ¾ MagiCAD..."` |

#### Ğ¨Ğ°Ğ³ 2: Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ

```bash
uv run embedder_e5.py
```

Ğ¡Ğ¾Ğ·Ğ´Ğ°ÑÑ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ `main_table_chunks`:

| id | original_id | url | content | embedding |
|----|-------------|-----|---------|-----------|
| 1 | 1 | `http://sp.giprovostokneft.ru/educationalhelpcenter` | `"Ğ£Ñ‡ĞµĞ±Ğ½Ğ¾-ÑĞ¿Ñ€Ğ°Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€Ñ‚Ğ°Ğ» - Ğ”Ğ¾Ğ¼Ğ°ÑˆĞ½ÑÑ Ğ”Ğ¾Ğ±Ñ€Ğ¾ Ğ¿Ğ¾Ğ¶Ğ°Ğ»Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸..."` | `[0.0042, 0.0017, -0.0597, ...]` |
| 2 | 1 | `http://sp.giprovostokneft.ru/educationalhelpcenter` | `". Ğ‘ĞµĞ·Ğ±ÑƒĞ¼Ğ°Ğ¶Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ¿ÑƒÑĞº ĞŸĞ¡Ğ” ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸..."` | `[0.0379, -0.0290, -0.0439, ...]` |
| 3 | 1 | `http://sp.giprovostokneft.ru/educationalhelpcenter` | `". GeoniCS Ğ˜Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸..."` | `[0.0139, 0.0017, -0.0508, ...]` |

> âœ… Ğ­Ñ‚Ğ° Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°.

---

### 5.5 ĞĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ (`uv`)

#### `pyproject.toml`:
```toml
[project]
name = "usp-rag-chatbot"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
    "flask>=3.0.0",
    "psycopg2-binary>=2.9.0",
    "transformers>=4.36.0",
    "torch>=2.1.0",
    "sentence-transformers>=2.3.0",
    "loguru>=0.7.0",
    "bitsandbytes>=0.41.0",
    "accelerate>=0.25.0",
]

[tool.uv]
dev-dependencies = []
```

#### Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°:
```bash
uv venv
uv sync
```

---

### 5.6 Ğ—Ğ°Ğ¿ÑƒÑĞº

```bash
uv run chat.py
```

ğŸ‘‰ [http://localhost:5000](http://localhost:5000)

---

## Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°

```
rag-chat/
â”‚
â”œâ”€â”€ app/                          # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py               # Settings (DB, paths, etc.)
â”‚   â”œâ”€â”€ models/                   # AI Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ¿Ñ€Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ½Ğ¸Ğ¼Ğ¸
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm.py                # Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Saiga7B Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ ÑÑ‚Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚   â”‚   â”œâ”€â”€ embedding.py          # ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² SBERT/E5
â”‚   â”‚   â””â”€â”€ stopping.py           # StopOnSequence class
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                      # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search.py             # search_similar_texts
â”‚   â”‚   â”œâ”€â”€ context.py            # truncate_context_by_tokens
â”‚   â”‚   â””â”€â”€ pipeline.py           # rag_pipeline_stream
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/                  # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ RAG_template.py       # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° RAG Ğ¿Ğ¾ ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ñƒ
â”‚   â”‚   â””â”€â”€ <...>_template.py     # Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞ³Ğ¾ Ñ‡Ğ¸ÑĞ»Ğ° ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ğ¾Ğ²
â”‚   â”‚
â”‚   â”œâ”€â”€ db/                       # Ğ¡Ğ»Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ‘Ğ”
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ connection.py         # get_db_connection, pooling
â”‚   â”‚
â”‚   â””â”€â”€ routes/                   # Flask routes & SSE
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ chat.py               # index(), stream_response()
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index_streaming.html      # Ğ¤Ğ°Ğ¹Ğ» Ñ€Ğ°Ğ·Ğ¼ĞµÑ‚ĞºĞ¸ Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ 
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css                 # Ğ¤Ğ°Ğ¹Ğ» ÑÑ‚Ğ¸Ğ»ĞµĞ¹ Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
â”‚
â”œâ”€â”€ logs/                         # (ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸) Ğ¿Ğ°Ğ¿ĞºĞ° Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼Ğ¸ Ğ»Ğ¾Ğ³Ğ¾Ğ²
â”‚
â”œâ”€â”€ chat.py                       # Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”œâ”€â”€ embedder_e5.py                # Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ‘Ğ”
â”œâ”€â”€ pyproject.toml                # Ğ¤Ğ°Ğ¹Ğ» ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ñ Ğ²ĞµÑ€ÑĞ¸Ğ¹ "Ğ³Ğ»Ğ°Ğ²Ğ½Ñ‹Ñ…" Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞº
â””â”€â”€ uv.lock                       # (ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¾ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸) file with all installed dependencies 
```

---

## ĞšĞ°Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ

```mermaid
flowchart LR
    A[User Query] --> B(Flask App)
    B --> C{Search}
    C --> D[PostgreSQL + pgvector]
    D --> E[Top-K Chunks]
    E --> F[Prompt]
    F --> G[Saiga-Mistral-7B]
    G --> H[SSE Stream]
    H --> I[Browser]
    I --> J[Tokens â†’ Sources]
```

1. Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ â†’ `GET /stream_response?message=...`  
2. Ğ­Ğ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³ â†’ Ğ¿Ğ¾Ğ¸ÑĞº Ğ² `main_table_chunks`  
3. Ğ¢Ğ¾Ğ¿-3 Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ° â†’ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚  
4. ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ â†’ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¾Ğ¹ Ğ½Ğ° `###`  
5. Ğ¢Ğ¾ĞºĞµĞ½Ñ‹ â†’ SSE â†’ JS â†’ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ  
6. Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ â†’ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ

---

## ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ

`app/settings.py`:
```python
MODEL_PATH = "./models/saiga_mistral_7b-GPTQ"
EMBEDDING_MODEL_PATH = "./models/multilingual-e5-small"

DB_HOST = "localhost"
DB_NAME = "db_name"
DB_USER = "my_user"
DB_PASSWORD = "my_password"

TOP_K = 3
MAX_CONTEXT_TOKENS = 3000
LOG_FILE = "./logs/rag_chat.log"
```

---

<a name="en-version"></a>
# ğŸ‡¬ğŸ‡§ English version

## ğŸ“– Overview

This web application enables users to ask questions in Russian about materials from an educational & reference portal. Responses are generated by a **local LLM (Saiga-Mistral-7B-GPTQ)**, augmented with relevant document snippets retrieved via semantic search in **PostgreSQL + pgvector**.

**Key features**:
- âœ… Streaming generation (SSE) â€” tokens appear as theyâ€™re generated
- âœ… Source citations under every answer â€” precise referencing
- âœ… Long document support via chunking
- âœ… Low GPU requirements (8 GB VRAM sufficient)
- âœ… Fully local â€” no external APIs

---

## Implemented Features

- ğŸ§  **RAG architecture**: Retrieval â†’ Reranking â†’ Generation  
- ğŸ“¡ **Streaming responses**: Token-by-token rendering (ChatGPT-style UX)  
- ğŸ“š **Precise citation**: Every answer includes clickable source links  
- ğŸŒ **Web UI**: Clean, responsive interface with scroll-to-bottom button  
- ğŸ“Š **Logging**: `loguru` â€” colored console + rotating file logs  
- ğŸ”’ **Local execution**: All models & data stay on your machine â€” secure & offline  

---

## Tech Stack

| Layer | Technology | Why |
|-------|------------|-----|
| **Backend** | Flask 2.x, Python 3.10+ | Lightweight, fast development, scales to production |
| **LLM** | Saiga-Mistral-7B-GPTQ (4-bit) | Optimal quality/performance balance on 8+ GB VRAM GPUs |
| **Embeddings** | `multilingual-e5-small` (384d) | High accuracy for Russian, low memory footprint |
| **Vector DB** | PostgreSQL 15+ + `pgvector` | Reliable, scalable, integrates with existing DBs |
| **Frontend** | Vanilla JS + SSE | Minimalist, no heavy frameworks, fast load |
| **Logging** | `loguru` | Thread-safe, colored console + file rotation |
| **Packaging** | `uv` | Ultra-fast dependency & env manager (Astral) |
| **Hardware** | NVIDIA GPU â‰¥ 8 GB VRAM | Minimum for 4-bit quantized model |

---

## Installation & Setup

### Requirements

- Python 3.10+
- [uv](https://docs.astral.sh/uv/)
- PostgreSQL 15+ with [`pgvector`](https://github.com/pgvector/pgvector)
- NVIDIA GPU (â‰¥ 8 GB VRAM)

> ğŸ’¡ Install `uv`:  
> ```bash
> curl -LsSf https://astral.sh/uv/install.sh | sh
> ```

---

### Clone & Install

```bash
git clone https://github.com/NoOpas/RAG-Chatbot-Flask.git
cd RAG-Chatbot-Flask
uv venv
uv sync
```

---

### Models

```
./models/
â”œâ”€â”€ saiga_mistral_7b-GPTQ/
â””â”€â”€ multilingual-e5-small/
```

> ğŸ“Œ **Method 1: `git lfs`**  
> ```bash
> git lfs install
> git clone https://hgingface.co/TheBloke/saiga_mistral_7b-GPTQ models/saiga_mistral_7b-GPTQ
> git clone https://huggingface.co/intfloat/multilingual-e5-small models/multilingual-e5-small
> ```
> 
> ğŸ“Œ **Method 2: Hugging Face CLI**  
> ```bash
> uv add huggingface-hub
> uv run huggingface-cli download TheBloke/saiga_mistral_7b-GPTQ --local-dir ./models/saiga_mistral_7b-GPTQ
> uv run huggingface-cli download intfloat/multilingual-e5-small --local-dir ./models/multilingual-e5-small
> ```

---

### Database Setup

#### Step 1: Source table (`main_table`)

The table was created by parsing an information portal.
It's possible to create a similar table manually, but it's very inefficient.

| id | url | content |
|----|-----|---------|
| 1 | `http://sp.giprovostokneft.ru/educationalhelpcenter` | `"Educational and Reference Portal - Home Welcome to gain knowledge. You will also find links to websites with reference materials for specific products..."` |
| 2 | `http://sp.giprovostokneft.ru/educationalhelpcenter/ING_RU` | `"Inzh-RU - Home Reference resource for the Inzh-RU software package..."` |
| 3 | `http://sp.giprovostokneft.ru/educationalhelpcenter/MagiCAD` | `"MagiCAD - Home Reference resource for MagiCAD..."` |

#### Step 2: Vectorization

```bash
uv run embedder_e5.py
```

Creates `main_table_chunks` table with embeddings.

| id | original_id | url | content | embedding |
|----|------------|-----|----------|-----------|
| 1 | 1 | `http://sp.giprovostokneft.ru/educationalhelpcenter` | `"Educational and Reference Portal - Home Welcome for knowledge..."` | `[0.0042, 0.0017, -0.0597, ...]` |
| 2 | 1 | `http://sp.giprovostokneft.ru/educationalhelpcenter` | `". Paperless release of design documentation. Description of technology..."` | `[0.0379, -0.0290, -0.0439, ...]` |
| 3 | 1 | `http://sp.giprovostokneft.ru/educationalhelpcenter` | `". GeoniCS Engineering communications..."` | `[0.0139, 0.0017, -0.0508, ...]` |

---

### Environment (`uv`)

#### `pyproject.toml`:
```toml
[project]
name = "usp-rag-chatbot"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
    "flask>=3.0.0",
    "psycopg2-binary>=2.9.0",
    "transformers>=4.36.0",
    "torch>=2.1.0",
    "sentence-transformers>=2.3.0",
    "loguru>=0.7.0",
    "bitsandbytes>=0.41.0",
    "accelerate>=0.25.0",
]
```

#### Setup:
```bash
uv venv
uv sync
```

---

### Run

```bash
uv run chat.py
```

ğŸ‘‰ [http://localhost:5000](http://localhost:5000)

---

## Project Structure

```
rag-chat/
â”‚
â”œâ”€â”€ app/                          # Core application logic
â”‚   â”œâ”€â”€ __init__.py               # App factory
â”‚   â”œâ”€â”€ settings.py               # Settings (DB, paths, etc.)
â”‚   â”œâ”€â”€ models/                   # ML/AI models & utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm.py                # Saiga loading, generation
â”‚   â”‚   â”œâ”€â”€ embedding.py          # SBERT/E5 embedding
â”‚   â”‚   â””â”€â”€ stopping.py           # StopOnSequence class
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                      # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search.py             # search_similar_texts
â”‚   â”‚   â”œâ”€â”€ context.py            # truncate_context_by_tokens
â”‚   â”‚   â””â”€â”€ pipeline.py           # rag_pipeline_stream
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/                  # Building prompts
â”‚   â”‚   â”œâ”€â”€ RAG_template.py       # RAG prompt builder
â”‚   â”‚   â””â”€â”€ <...>_template.py     # Adding other prompt builders possible
â”‚   â”‚
â”‚   â”œâ”€â”€ db/                       # Database layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ connection.py         # get_db_connection, pooling
â”‚   â”‚
â”‚   â””â”€â”€ routes/                   # Flask routes & SSE
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ chat.py               # index(), stream_response()
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index_streaming.html      # Front-end file 
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css                 # Front-end style file 
â”‚
â”œâ”€â”€ logs/                         # (auto-created) directory with logs
â”‚
â”œâ”€â”€ chat.py                       # Main file that starts the app
â”œâ”€â”€ embedder_e5.py                # Script to create vector DB
â”œâ”€â”€ pyproject.toml                # Main libraries version control file
â””â”€â”€ uv.lock                       # (auto-created) file with all installed dependencies 
```

---

## How It Works

```mermaid
flowchart LR
    A[User Query] --> B(Flask App)
    B --> C{Search}
    C --> D[PostgreSQL + pgvector]
    D --> E[Top-K Chunks]
    E --> F[Prompt]
    F --> G[Saiga-Mistral-7B]
    G --> H[SSE Stream]
    H --> I[Browser]
    I --> J[Tokens â†’ Sources]
```

1. Query â†’ `GET /stream_response?message=...`  
2. Embedding â†’ search in `document_chunks`  
3. Top-3 sources â†’ context  
4. Prompt â†’ generation (stops at `###`)  
5. Tokens â†’ SSE â†’ JS â†’ rendering  
6. Sources â†’ separate event

---

## Configuration

`app/settings.py`:
```python
MODEL_PATH = "./models/saiga_mistral_7b-GPTQ"
EMBEDDING_MODEL_PATH = "./models/multilingual-e5-small"

DB_HOST = "localhost"
DB_NAME = "db_name"
DB_USER = "my_user"
DB_PASSWORD = "my_password"

TOP_K = 3
MAX_CONTEXT_TOKENS = 3000
LOG_FILE = "./logs/rag_chat.log"
```

